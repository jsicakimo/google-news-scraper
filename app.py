from flask import Flask, render_template, request, send_file, url_for
import feedparser
import pandas as pd
from datetime import datetime
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt
from io import BytesIO
import os
import traceback

try:
    from wordcloud import WordCloud, STOPWORDS

    WORDCLOUD_AVAILABLE = True
except ImportError:
    WORDCLOUD_AVAILABLE = False
    print("âš ï¸ æœªå®‰è£ wordcloud æ¨¡çµ„ï¼Œè©é›²åŠŸèƒ½å°‡è¢«ç¦ç”¨")

try:
    from snownlp import SnowNLP

    SENTIMENT_AVAILABLE = True
except ImportError:
    SENTIMENT_AVAILABLE = False
    print("âš ï¸ æœªå®‰è£ snownlp æ¨¡çµ„ï¼Œæƒ…æ„Ÿåˆ†æåŠŸèƒ½å°‡è¢«ç¦ç”¨")

# ğŸ”§ ç¢ºä¿ static è³‡æ–™å¤¾å­˜åœ¨
os.makedirs("static", exist_ok=True)
print(f"âœ… Static è³‡æ–™å¤¾è·¯å¾‘: {os.path.abspath('static')}")

app = Flask(__name__)


def build_rss_url(keyword):
    base = "https://news.google.com/rss/search"
    return f"{base}?q={keyword}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"


def fetch_rss_news(keyword, start_date, end_date, logic="AND"):
    """
    æŠ“å– RSS æ–°èï¼Œæ”¯æ´å¤šé—œéµå­—å’Œ AND/OR é‚è¼¯
    :param keyword: é—œéµå­—ï¼ˆå¯ç‚ºé€—è™Ÿæˆ–ç©ºæ ¼åˆ†éš”çš„å¤šå€‹é—œéµå­—ï¼‰
    :param start_date: é–‹å§‹æ—¥æœŸ
    :param end_date: çµæŸæ—¥æœŸ
    :param logic: é‚è¼¯é‹ç®—ç¬¦ï¼ˆAND/ORï¼‰
    :return: æ–°èåˆ—è¡¨
    """
    keywords = [k.strip() for k in keyword.replace(",", " ").split() if k.strip()]
    results = []

    for kw in keywords:
        rss_url = build_rss_url(kw)
        feed = feedparser.parse(rss_url)
        for entry in feed.entries:
            published = datetime(*entry.published_parsed[:6])
            if start_date <= published.date() <= end_date:
                news_item = {
                    "æ¨™é¡Œ": entry.title,
                    "é€£çµ": entry.link,
                    "ç™¼å¸ƒæ™‚é–“": published.strftime("%Y-%m-%d %H:%M:%S"),
                    "ä¾†æº": entry.source.title if "source" in entry else "æœªçŸ¥",
                    "é—œéµå­—": kw,
                }
                results.append(news_item)

    # æ ¹æ“šé‚è¼¯é‹ç®—ç¬¦éæ¿¾çµæœ
    if logic == "AND" and len(keywords) > 1:
        # åªä¿ç•™åŒ…å«æ‰€æœ‰é—œéµå­—çš„æ–°è
        filtered_results = []
        for item in results:
            if all(kw in item["æ¨™é¡Œ"] for kw in keywords):
                filtered_results.append(item)
        results = filtered_results

    return results


def generate_pie_chart(df):
    """ç”Ÿæˆåœ“é¤…åœ–ä¸¦è¿”å›æª”æ¡ˆåç¨±ï¼ˆç›¸å°æ–¼ static è³‡æ–™å¤¾ï¼‰"""
    try:
        print("ğŸ¨ é–‹å§‹ç”Ÿæˆåœ“é¤…åœ–...")

        count_data = df["ä¾†æº"].value_counts()
        print(f"ğŸ“Š çµ±è¨ˆè³‡æ–™: {count_data.to_dict()}")

        # å»ºç«‹åœ–è¡¨
        fig = plt.figure(figsize=(12, 8))
        ax = fig.add_subplot(111)

        # è¨­å®šä¸­æ–‡å­—é«”
        plt.rcParams["font.sans-serif"] = [
            "Microsoft JhengHei",
            "SimHei",
            "Arial Unicode MS",
            "sans-serif",
        ]
        plt.rcParams["axes.unicode_minus"] = False

        # ç”Ÿæˆé¡è‰²æ–¹æ¡ˆ
        colors = plt.cm.Set3(range(len(count_data)))

        # ç¹ªè£½åœ“é¤…åœ–
        wedges, texts, autotexts = ax.pie(
            count_data.values,
            labels=count_data.index,
            autopct="%1.1f%%",
            startangle=90,
            colors=colors,
            textprops={"fontsize": 11},
            pctdistance=0.85,
        )

        # è¨­å®šæ¨™é¡Œ
        ax.set_title("å„æ–°èä¾†æºç¯‡æ•¸çµ±è¨ˆ", fontsize=18, pad=20, fontweight="bold")

        # ç¾åŒ–ç™¾åˆ†æ¯”æ–‡å­—
        for autotext in autotexts:
            autotext.set_color("white")
            autotext.set_fontweight("bold")
            autotext.set_fontsize(11)

        # æ·»åŠ åœ–ä¾‹
        legend_labels = [f"{source}: {count}ç¯‡" for source, count in count_data.items()]
        ax.legend(
            legend_labels, loc="center left", bbox_to_anchor=(1, 0.5), fontsize=11
        )

        # ç¢ºä¿åœ“é¤…åœ–æ˜¯æ­£åœ“å½¢
        ax.axis("equal")

        plt.tight_layout()

        # ç”Ÿæˆå”¯ä¸€çš„æª”æ¡ˆåç¨±
        chart_filename = f"chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        chart_path = os.path.join("static", chart_filename)

        print(f"ğŸ’¾ æº–å‚™å„²å­˜åœ–è¡¨åˆ°: {os.path.abspath(chart_path)}")

        # å„²å­˜åœ–è¡¨
        plt.savefig(chart_path, dpi=120, bbox_inches="tight", facecolor="white")
        plt.close(fig)

        # é©—è­‰æª”æ¡ˆæ˜¯å¦æˆåŠŸå‰µå»º
        if os.path.exists(chart_path):
            file_size = os.path.getsize(chart_path)
            print(f"âœ… åœ“é¤…åœ–å·²æˆåŠŸç”Ÿæˆ: {chart_path} (å¤§å°: {file_size} bytes)")
            return chart_filename
        else:
            print(f"âŒ éŒ¯èª¤ï¼šåœ–è¡¨æª”æ¡ˆæœªèƒ½å‰µå»ºï¼")
            return None

    except Exception as e:
        print(f"âŒ ç”Ÿæˆåœ“é¤…åœ–æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        print(f"è©³ç´°éŒ¯èª¤è¨Šæ¯:\n{traceback.format_exc()}")
        return None


# def generate_trend_chart(df):
#     """ç”Ÿæˆæ™‚é–“è¶¨å‹¢åœ–ä¸¦è¿”å›æª”æ¡ˆåç¨±ï¼ˆç›¸å°æ–¼ static è³‡æ–™å¤¾ï¼‰"""
#     try:
#         print("ğŸ“ˆ é–‹å§‹ç”Ÿæˆæ™‚é–“è¶¨å‹¢åœ–...")

#         # å°‡ç™¼å¸ƒæ™‚é–“è½‰æ›ç‚ºæ—¥æœŸæ ¼å¼
#         df["æ—¥æœŸ"] = pd.to_datetime(df["ç™¼å¸ƒæ™‚é–“"]).dt.date

#         # çµ±è¨ˆæ¯æ—¥æ–°èæ•¸é‡
#         trend_data = df["æ—¥æœŸ"].value_counts().sort_index()
#         print(f"ğŸ“Š æ™‚é–“è¶¨å‹¢è³‡æ–™: {trend_data.to_dict()}")

#         # å»ºç«‹åœ–è¡¨
#         fig = plt.figure(figsize=(12, 6))
#         ax = fig.add_subplot(111)

#         # ç¹ªè£½æŠ˜ç·šåœ–
#         ax.plot(
#             trend_data.index, trend_data.values, marker="o", linestyle="-", color="b"
#         )
#         ax.set_title("æ–°èæ•¸é‡æ™‚é–“è¶¨å‹¢")
#         ax.set_xlabel("æ—¥æœŸ")
#         ax.set_ylabel("æ–°èæ•¸é‡")
#         plt.xticks(rotation=45)

#         # å„²å­˜åœ–è¡¨
#         chart_filename = "trend_chart.png"
#         chart_path = os.path.join("static", chart_filename)
#         plt.savefig(chart_path, bbox_inches="tight")
#         plt.close()

#         # è¿”å›ç›¸å°æ–¼ static çš„æª”æ¡ˆåç¨±
#         return chart_filename
#     except Exception as e:
#         print(f"âŒ ç”Ÿæˆæ™‚é–“è¶¨å‹¢åœ–å¤±æ•—: {e}")
#         traceback.print_exc()
#         return None


def generate_word_cloud(df):
    """ç”Ÿæˆé—œéµå­—é›²ä¸¦è¿”å›æª”æ¡ˆåç¨±ï¼ˆç›¸å°æ–¼ static è³‡æ–™å¤¾ï¼‰"""
    if not WORDCLOUD_AVAILABLE:
        print("âš ï¸ è©é›²åŠŸèƒ½æœªå•Ÿç”¨ï¼Œè«‹å®‰è£ wordcloud æ¨¡çµ„")
        return None
    try:
        print("â˜ï¸ é–‹å§‹ç”Ÿæˆé—œéµå­—é›²...")

        # æå–æ‰€æœ‰æ¨™é¡Œ
        titles = " ".join(df["æ¨™é¡Œ"].tolist())

        # ğŸ”§ ä¿®å¾©ï¼šæ­£ç¢ºå»ºç«‹åœç”¨è©é›†åˆ
        # STOPWORDS.update() è¿”å› Noneï¼Œæ‡‰è©²ä½¿ç”¨é›†åˆé‹ç®—
        chinese_stopwords = {
            "çš„",
            "æ˜¯",
            "åœ¨",
            "äº†",
            "å’Œ",
            "æœ‰",
            "ä¹Ÿ",
            "ç‚º",
            "èˆ‡",
            "ç­‰",
            "å°‡",
            "åŠ",
            "æˆ–",
            "ä½†",
            "è€Œ",
            "å°",
            "æ–¼",
            "ä»¥",
            "ä¸­",
            "åˆ°",
            "å¾",
            "è¢«",
            "æŠŠ",
            "è®“",
            "ä½¿",
            "ç”±",
            "å‘",
            "å°±",
            "éƒ½",
            "è¦",
            "æœƒ",
            "èƒ½",
            "å¯",
            "ä¸",
            "æ²’",
            "å¾ˆ",
            "æ›´",
            "æœ€",
            "é",
            "å†",
            "åˆ",
            "é‚„",
            "å·²",
            "æ›¾",
            "æ­£",
            "è©²",
            "æ­¤",
            "å…¶",
            "é€™",
            "é‚£",
            "äº›",
            "å€‹",
            "ä½",
            "å",
        }

        # åˆä½µè‹±æ–‡å’Œä¸­æ–‡åœç”¨è©
        # æ­£ç¢ºå¯«æ³•ï¼ˆè¿”å›é›†åˆï¼‰
        all_stopwords = STOPWORDS | chinese_stopwords
        
        # ğŸ¨ å˜—è©¦å¤šå€‹å¯èƒ½çš„ä¸­æ–‡å­—é«”è·¯å¾‘ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
        font_paths = [
            "C:\\Windows\\Fonts\\msjh.ttc",  # Windows - å¾®è»Ÿæ­£é»‘é«”
            "C:\\Windows\\Fonts\\msyh.ttc",  # Windows - å¾®è»Ÿé›…é»‘
            "/System/Library/Fonts/PingFang.ttc",  # macOS - è˜‹æ–¹
            "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",  # Linux
            "msyh.ttc",  # ç›¸å°è·¯å¾‘
        ]

        font_path = None
        for path in font_paths:
            if os.path.exists(path):
                font_path = path
                print(f"âœ… æ‰¾åˆ°å­—é«”æª”æ¡ˆ: {path}")
                break

        if not font_path:
            print("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨é è¨­å­—é«”ï¼ˆå¯èƒ½ç„¡æ³•æ­£ç¢ºé¡¯ç¤ºä¸­æ–‡ï¼‰")

        # ä½¿ç”¨ wordcloud ç”Ÿæˆè©é›²
        wordcloud_params = {
            "width": 1200,
            "height": 600,
            "background_color": "white",
            "stopwords": all_stopwords,
            "max_words": 100,
            "relative_scaling": 0.3,
            "min_font_size": 10,
        }

        # åªåœ¨æ‰¾åˆ°å­—é«”æ™‚æ‰è¨­å®š font_path
        if font_path:
            wordcloud_params["font_path"] = font_path

        wordcloud = WordCloud(**wordcloud_params).generate(titles)

        # ğŸ”§ ç”Ÿæˆå”¯ä¸€çš„æª”æ¡ˆåç¨±ï¼ˆé¿å…è¦†è“‹ï¼‰
        wordcloud_filename = f"wordcloud_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        wordcloud_path = os.path.join("static", wordcloud_filename)
        wordcloud.to_file(wordcloud_path)

        # é©—è­‰æª”æ¡ˆæ˜¯å¦æˆåŠŸå‰µå»º
        if os.path.exists(wordcloud_path):
            file_size = os.path.getsize(wordcloud_path)
            print(f"âœ… è©é›²å·²æˆåŠŸç”Ÿæˆ: {wordcloud_path} (å¤§å°: {file_size} bytes)")
            return wordcloud_filename
        else:
            print(f"âŒ éŒ¯èª¤ï¼šè©é›²æª”æ¡ˆæœªèƒ½å‰µå»ºï¼")
            return None

    except Exception as e:
        print(f"âŒ ç”Ÿæˆé—œéµå­—é›²å¤±æ•—: {e}")
        traceback.print_exc()
        return None


def analyze_sentiment(text):
    """
    åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå‚¾å‘
    :param text: è¦åˆ†æçš„æ–‡æœ¬
    :return: æƒ…æ„Ÿåˆ†æ•¸ (0-1)ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºè¶Šæ­£é¢
    """
    if not SENTIMENT_AVAILABLE:
        return None
    try:
        s = SnowNLP(text)
        return s.sentiments
    except Exception as e:
        print(f"âŒ æƒ…æ„Ÿåˆ†æå¤±æ•—: {e}")
        return None


def classify_sentiment(score):
    """
    æ ¹æ“šæƒ…æ„Ÿåˆ†æ•¸åˆ†é¡
    :param score: æƒ…æ„Ÿåˆ†æ•¸ (0-1)
    :return: æƒ…æ„Ÿåˆ†é¡ ('æ­£é¢', 'ä¸­ç«‹', 'è² é¢')
    """
    if score is None:
        return "æœªçŸ¥"
    if score >= 0.6:
        return "æ­£é¢"
    elif score <= 0.4:
        return "è² é¢"
    else:
        return "ä¸­ç«‹"


def analyze_news_sentiment(df):
    """
    åˆ†ææ–°èåˆ—è¡¨çš„æƒ…æ„Ÿå‚¾å‘
    :param df: æ–°è DataFrame
    :return: åŒ…å«æƒ…æ„Ÿåˆ†æçµæœçš„ DataFrame
    """
    if not SENTIMENT_AVAILABLE:
        print("âš ï¸ æƒ…æ„Ÿåˆ†æåŠŸèƒ½æœªå•Ÿç”¨")
        return df

    try:
        print("ğŸ’­ é–‹å§‹é€²è¡Œæƒ…æ„Ÿåˆ†æ...")

        # åˆ†ææ¯æ¢æ–°èçš„æƒ…æ„Ÿ
        sentiment_scores = []
        sentiment_labels = []

        for title in df["æ¨™é¡Œ"]:
            score = analyze_sentiment(title)
            sentiment_scores.append(score)
            sentiment_labels.append(classify_sentiment(score))

        df["æƒ…æ„Ÿåˆ†æ•¸"] = sentiment_scores
        df["æƒ…æ„Ÿåˆ†é¡"] = sentiment_labels

        print(f"âœ… æƒ…æ„Ÿåˆ†æå®Œæˆ")
        print(f"ğŸ“Š æƒ…æ„Ÿåˆ†ä½ˆ: {pd.Series(sentiment_labels).value_counts().to_dict()}")

        return df
    except Exception as e:
        print(f"âŒ æƒ…æ„Ÿåˆ†æå¤±æ•—: {e}")
        traceback.print_exc()
        return df


def generate_sentiment_chart(df):
    """ç”Ÿæˆæƒ…æ„Ÿåˆ†æåœ–è¡¨ä¸¦è¿”å›æª”æ¡ˆåç¨±"""
    if not SENTIMENT_AVAILABLE or "æƒ…æ„Ÿåˆ†é¡" not in df.columns:
        print("âš ï¸ ç„¡æ³•ç”Ÿæˆæƒ…æ„Ÿåˆ†æåœ–è¡¨")
        return None

    try:
        print("ğŸ“Š é–‹å§‹ç”Ÿæˆæƒ…æ„Ÿåˆ†æåœ–è¡¨...")

        # çµ±è¨ˆæƒ…æ„Ÿåˆ†ä½ˆ
        sentiment_counts = df["æƒ…æ„Ÿåˆ†é¡"].value_counts()
        print(f"ğŸ“Š æƒ…æ„Ÿçµ±è¨ˆ: {sentiment_counts.to_dict()}")

        # å»ºç«‹åœ–è¡¨
        fig = plt.figure(figsize=(10, 6))
        ax = fig.add_subplot(111)

        # è¨­å®šä¸­æ–‡å­—é«”
        plt.rcParams["font.sans-serif"] = [
            "Microsoft JhengHei",
            "SimHei",
            "Arial Unicode MS",
            "sans-serif",
        ]
        plt.rcParams["axes.unicode_minus"] = False

        # å®šç¾©é¡è‰²
        colors = {
            "æ­£é¢": "#2ecc71",
            "ä¸­ç«‹": "#f39c12",
            "è² é¢": "#e74c3c",
            "æœªçŸ¥": "#95a5a6",
        }
        bar_colors = [colors.get(label, "#95a5a6") for label in sentiment_counts.index]

        # ç¹ªè£½æŸ±ç‹€åœ–
        bars = ax.bar(
            sentiment_counts.index,
            sentiment_counts.values,
            color=bar_colors,
            edgecolor="black",
            linewidth=1.5,
        )

        # è¨­å®šæ¨™é¡Œå’Œæ¨™ç±¤
        ax.set_title("æ–°èæƒ…æ„Ÿåˆ†æåˆ†ä½ˆ", fontsize=16, fontweight="bold", pad=20)
        ax.set_xlabel("æƒ…æ„Ÿåˆ†é¡", fontsize=12, fontweight="bold")
        ax.set_ylabel("æ–°èæ•¸é‡", fontsize=12, fontweight="bold")

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•¸å€¼
        for bar in bars:
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height,
                f"{int(height)}",
                ha="center",
                va="bottom",
                fontweight="bold",
                fontsize=11,
            )

        # æ·»åŠ ç¶²æ ¼
        ax.grid(axis="y", alpha=0.3, linestyle="--")
        ax.set_axisbelow(True)

        plt.tight_layout()

        # ç”Ÿæˆå”¯ä¸€çš„æª”æ¡ˆåç¨±
        chart_filename = f"sentiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        chart_path = os.path.join("static", chart_filename)

        # å„²å­˜åœ–è¡¨
        plt.savefig(chart_path, dpi=120, bbox_inches="tight", facecolor="white")
        plt.close(fig)

        if os.path.exists(chart_path):
            file_size = os.path.getsize(chart_path)
            print(f"âœ… æƒ…æ„Ÿåˆ†æåœ–è¡¨å·²æˆåŠŸç”Ÿæˆ: {chart_path} (å¤§å°: {file_size} bytes)")
            return chart_filename
        else:
            print(f"âŒ éŒ¯èª¤ï¼šæƒ…æ„Ÿåˆ†æåœ–è¡¨æª”æ¡ˆæœªèƒ½å‰µå»ºï¼")
            return None

    except Exception as e:
        print(f"âŒ ç”Ÿæˆæƒ…æ„Ÿåˆ†æåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        print(f"è©³ç´°éŒ¯èª¤è¨Šæ¯:\n{traceback.format_exc()}")
        return None


@app.route("/")
def index():
    return render_template("index.html")


@app.route("/scrape", methods=["POST"])
def scrape():
    # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨ .get() ç²å–è¡¨å–®è³‡æ–™ï¼Œå¢åŠ ç¨‹å¼ç¢¼å¥å£¯æ€§
    keyword = request.form.get("keyword", "").strip()
    start_date_str = request.form.get("start_date")
    end_date_str = request.form.get("end_date")
    logic = request.form.get("logic", "AND")

    if not all([keyword, start_date_str, end_date_str]):
        return render_template("index.html", error="è«‹ç¢ºä¿æ‰€æœ‰æ¬„ä½éƒ½å·²å¡«å¯«ï¼")

    try:
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date()
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()
    except (ValueError, TypeError):
        return render_template("index.html", error="æ—¥æœŸæ ¼å¼ä¸æ­£ç¢ºï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ã€‚")
    if start_date > end_date:
        return render_template("index.html", error="èµ·å§‹æ—¥æœŸä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸã€‚")

    # æŠ“å–æ–°è
    news_items = fetch_rss_news(keyword, start_date, end_date, logic)
    df = pd.DataFrame(news_items)

    # ğŸ”§ ä¿®å¾©ï¼šå¦‚æœæ‰¾ä¸åˆ°ä»»ä½•æ–°èï¼Œdf æœƒæ˜¯ç©ºçš„ï¼Œç›´æ¥è¿”å›çµæœé é¢ä¸¦é¡¯ç¤ºæç¤º
    if df.empty:
        print("âš ï¸ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„æ–°èï¼Œè¿”å›çµæœé é¢ã€‚")
        return render_template("results.html", keyword=keyword, count=0, results=[])

    # é€²è¡Œæƒ…æ„Ÿåˆ†æ
    df = analyze_news_sentiment(df)

    # ğŸ”§ ä¿®æ­£ï¼šæº–å‚™çµ¦ Chart.js çš„åœ“é¤…åœ–æ•¸æ“šï¼Œè€Œä¸æ˜¯ç”Ÿæˆåœ–ç‰‡
    pie_chart_data = None
    if not df.empty:
        source_counts = df["ä¾†æº"].value_counts()
        pie_chart_data = {
            "labels": source_counts.index.tolist(),
            "data": source_counts.values.tolist(),
        }

    # ğŸ”§ æ–°å¢ï¼šæº–å‚™çµ¦ Chart.js çš„æ™‚é–“è¶¨å‹¢åœ–æ•¸æ“š
    trend_chart_data = None
    if not df.empty:
        df["æ—¥æœŸ"] = pd.to_datetime(df["ç™¼å¸ƒæ™‚é–“"]).dt.date # ç¢ºä¿æ—¥æœŸæ¬„ä½å­˜åœ¨
        trend_counts = df["æ—¥æœŸ"].value_counts().sort_index()
        trend_chart_data = {
            "labels": [date.strftime("%Y-%m-%d") for date in trend_counts.index], # æ—¥æœŸæ ¼å¼åŒ–ç‚ºå­—ä¸²
            "data": [int(count) for count in trend_counts.values], # è½‰æ›ç‚º Python åŸç”Ÿ int
        }

    # ğŸ”§ æ–°å¢ï¼šæº–å‚™çµ¦ Chart.js çš„æƒ…æ„Ÿé•·æ¢åœ–æ•¸æ“š
    sentiment_chart_data = None
    if "æƒ…æ„Ÿåˆ†é¡" in df.columns:
        sentiment_counts = df["æƒ…æ„Ÿåˆ†é¡"].value_counts()
        # ç‚ºäº†å›ºå®šçš„é¡è‰²é †åºï¼Œæˆ‘å€‘å®šç¾©ä¸€å€‹æ¨™ç±¤é †åº
        # ç¢ºä¿ 'æœªçŸ¥' æƒ…æ„Ÿåˆ†é¡ä¹ŸåŒ…å«åœ¨å…§ï¼Œå³ä½¿æ²’æœ‰æ•¸æ“šï¼Œä»¥ä¾¿é¡è‰²æ˜ å°„ä¸€è‡´
        # é€™è£¡çš„ labels_order æ‡‰è©²èˆ‡ classify_sentiment å‡½å¼ä¸­çš„åˆ†é¡ä¸€è‡´
        labels_order = ["æ­£é¢", "ä¸­ç«‹", "è² é¢", "æœªçŸ¥"]
        chart_labels = [label for label in labels_order if label in sentiment_counts.index]
        # ğŸ”§ ä¿®æ­£ï¼šå°‡ numpy.int64 è½‰æ›ç‚º python åŸç”Ÿçš„ int
        chart_data = [int(sentiment_counts[label]) for label in chart_labels]
        sentiment_chart_data = {
            "labels": chart_labels,
            "data": chart_data,
        }

    # ç”Ÿæˆå…¶ä»–åœ–è¡¨
    # pie_chart = generate_pie_chart(df) # ä¸å†éœ€è¦ç”Ÿæˆéœæ…‹åœ“é¤…åœ–
    # trend_chart = generate_trend_chart(df) # ä¸å†éœ€è¦ç”Ÿæˆéœæ…‹è¶¨å‹¢åœ–
    wordcloud = generate_word_cloud(df)
    # sentiment_chart = generate_sentiment_chart(df) # ä¸å†éœ€è¦ç”Ÿæˆéœæ…‹æƒ…æ„Ÿåœ–

    # å„²å­˜ç‚º Excel
    file_name = f"news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    df.to_excel(os.path.join("static", file_name), index=False)

    # ç²å–æ‰€æœ‰æ–°èä¾†æº
    sources = df["ä¾†æº"].unique().tolist()

    # è¨ˆç®—æƒ…æ„Ÿçµ±è¨ˆ
    sentiment_stats = {}
    if "æƒ…æ„Ÿåˆ†é¡" in df.columns:
        sentiment_counts = df["æƒ…æ„Ÿåˆ†é¡"].value_counts()
        sentiment_stats = sentiment_counts.to_dict()

    # å°‡ DataFrame è½‰æ›å›åˆ—è¡¨ï¼ŒåŒ…å«æƒ…æ„Ÿåˆ†æçµæœ
    results_with_sentiment = df.to_dict("records")

    return render_template(
        "results.html",
        keyword=keyword,
        results=results_with_sentiment,
        count=len(results_with_sentiment),
        file_name=file_name,
        pie_chart_data=pie_chart_data,
        trend_chart_data=trend_chart_data, # å‚³éæ•¸æ“š
        wordcloud=wordcloud,
        sentiment_chart_data=sentiment_chart_data, # å‚³éæ•¸æ“š
        sentiment_stats=sentiment_stats,
        sources=sources,
    )


@app.route("/download/<filename>")
def download(filename):
    return send_file(os.path.join("static", filename), as_attachment=True)


if __name__ == "__main__":
    app.run(debug=True)